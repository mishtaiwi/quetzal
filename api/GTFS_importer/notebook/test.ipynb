{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "45cc632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import gtfs_kit as gtk\n",
    "import numpy as np\n",
    "sys.path.insert(0, r'../../../')\n",
    "from quetzal.io.gtfs_reader import importer\n",
    "from quetzal.io.gtfs_reader.frequencies import hhmmss_to_seconds_since_midnight \n",
    "from quetzal.model import stepmodel\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70448612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a35e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6f0f96a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_range = ['6:00:00', '8:59:00'] # PPAM\n",
    "#dates = ['20191015'] # the dates must be within the feed start and end dates\n",
    "#https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.weekday.html\n",
    "day = 'tuesday'\n",
    "day_dict = {\n",
    "    'monday': 0,\n",
    "    'tuesday': 1,\n",
    "    'wednesday': 2,\n",
    "    'thursday': 3,\n",
    "    'friday': 4,\n",
    "    'saturday': 5,\n",
    "    'sunday': 6\n",
    "}\n",
    "selected_day = day_dict[day]\n",
    "selected_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d24a503f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gtfs/cmm/stl.zip']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GTFS are read recursively between each ancestor\n",
    "files=[]\n",
    "gtfs_folder = 'gtfs/cmm/'\n",
    "if os.path.exists(gtfs_folder):\n",
    "    for filename in filter(lambda x: x[-4:] == '.zip', os.listdir(gtfs_folder)):\n",
    "        files.append(gtfs_folder+filename)\n",
    "\n",
    "#files = files[0:1]\n",
    "files=[files[2]]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b89b0fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfiles = [\\n    \"https://storage.googleapis.com/storage/v1/b/mdb-latest/o/ca-unknown-via-rail-canada-gtfs-735.zip?alt=media\",\\n    \"https://storage.googleapis.com/storage/v1/b/mdb-latest/o/ca-quebec-exo-sorel-varennes-gtfs-741.zip?alt=media\",\\n    \"https://storage.googleapis.com/storage/v1/b/mdb-latest/o/ca-quebec-exo-sud-ouest-gtfs-742.zip?alt=media\",\\n    \"https://storage.googleapis.com/storage/v1/b/mdb-latest/o/ca-quebec-exo-la-presquile-gtfs-743.zip?alt=media\"\\n]\\nfiles = [\"https://storage.googleapis.com/storage/v1/b/mdb-latest/o/ca-british-columbia-translink-vancouver-gtfs-1222.zip?alt=media\"]\\n'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "files = [\n",
    "    \"https://storage.googleapis.com/storage/v1/b/mdb-latest/o/ca-unknown-via-rail-canada-gtfs-735.zip?alt=media\",\n",
    "    \"https://storage.googleapis.com/storage/v1/b/mdb-latest/o/ca-quebec-exo-sorel-varennes-gtfs-741.zip?alt=media\",\n",
    "    \"https://storage.googleapis.com/storage/v1/b/mdb-latest/o/ca-quebec-exo-sud-ouest-gtfs-742.zip?alt=media\",\n",
    "    \"https://storage.googleapis.com/storage/v1/b/mdb-latest/o/ca-quebec-exo-la-presquile-gtfs-743.zip?alt=media\"\n",
    "]\n",
    "files = [\"https://storage.googleapis.com/storage/v1/b/mdb-latest/o/ca-british-columbia-translink-vancouver-gtfs-1222.zip?alt=media\"]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ddd0eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"https://storage.googleapis.com/storage/v1/b/mdb-latest/o/ca-british-columbia-translink-vancouver-gtfs-1222.zip?alt=media\",'gtfs/cmm/stl.zip']\n",
    "files=['https://storage.googleapis.com/storage/v1/b/mdb-latest/o/ca-unknown-via-rail-canada-gtfs-735.zip?alt=media']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb5f6f3",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "00b44232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing https://storage.googleapis.com/storage/v1/b/mdb-latest/o/ca-unknown-via-rail-canada-gtfs-735.zip?alt=media.zip\n"
     ]
    }
   ],
   "source": [
    "feeds=[]\n",
    "for file in files:\n",
    "    print('Importing {f}.zip'.format(f=file))\n",
    "    feeds.append(importer.GtfsImporter(path=file, dist_units='m'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a3cfe0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.googleapis.com/storage/v1/b/mdb-latest/o/ca-unknown-via-rail-canada-gtfs-735.zip?alt=media\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(feeds)):\n",
    "    print(files[i])\n",
    "    if 'agency_id' not in feeds[i].routes:\n",
    "        print(f'add agency_id to routes in {files[i]}')\n",
    "        feeds[i].routes['agency_id'] = feeds[i].agency['agency_id'].values[0]\n",
    "    \n",
    "    if 'pickup_type' not in feeds[i].stop_times:\n",
    "        print(f'picjup_type missing in stop_times. set to 0 in {files[i]}')\n",
    "        feeds[i].stop_times['pickup_type'] = 0\n",
    "    \n",
    "    if 'drop_off_type' not in feeds[i].stop_times:\n",
    "        print(f'drop_odd_type missing in stop_times. set to 0 in {files[i]}')\n",
    "        feeds[i].stop_times['drop_off_type'] = 0\n",
    "        \n",
    "    if 'parent_station' not in feeds[i].stops:\n",
    "        print(f'parent_station missing in stops. set to NaN in {files[i]}')\n",
    "        feeds[i].stops['parent_station'] = np.nan\n",
    "        \n",
    "    feeds[i].stop_times['pickup_type'].fillna(0, inplace=True)\n",
    "    feeds[i].stop_times['drop_off_type'].fillna(0, inplace=True)\n",
    "    feeds[i].stop_times['arrival_time'] = feeds[i].stop_times['departure_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7a0447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc56e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbb12352",
   "metadata": {},
   "source": [
    "# filtres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ebc3b4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dates =[]\n",
    "for feed in feeds:\n",
    "    min_date = feed.calendar['start_date'].unique().min()\n",
    "    max_date = feed.calendar['end_date'].unique().max()\n",
    "    # get date range \n",
    "    s = pd.date_range(min_date, max_date, freq='D').to_series()\n",
    "    # get dayofweek selected and take first one\n",
    "    s = s[s.dt.dayofweek==selected_day][0]\n",
    "    # format  ex: ['20231011'] and append\n",
    "    dates.append([f'{s.year}{str(s.month).zfill(2)}{str(s.day).zfill(2)}'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf817db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec8be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bb4a6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "feeds_t = []\n",
    "\n",
    "for i, feed in enumerate(feeds):\n",
    "    feed_t = feed.restrict(dates=dates[i], time_range=time_range)\n",
    "    if len(feed_t.trips) > 0:\n",
    "        feeds_t.append(feed_t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a26cc461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c8029361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add shape_dist_traveled to shapes\n"
     ]
    }
   ],
   "source": [
    "print('add shape_dist_traveled to shapes')\n",
    "for feed in feeds_t:\n",
    "    if 'shape_dist_traveled' not in feed.shapes.columns:\n",
    "        feed.append_dist_to_shapes\n",
    "    elif any(feed.shapes['shape_dist_traveled'].isnull()):\n",
    "        feed.append_dist_to_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ca3b5369",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feed in feeds_t:\n",
    "    if 'shape_dist_traveled' not in feed.stop_times.columns:\n",
    "        feed.append_dist_to_stop_times_fast()\n",
    "    else:\n",
    "        nan_sequence=feed.stop_times[feed.stop_times['shape_dist_traveled'].isnull()]['stop_sequence'].unique()\n",
    "        if all(seq==1 for seq in nan_sequence):\n",
    "            feed.stop_times['shape_dist_traveled'] = feed.stop_times['shape_dist_traveled'].fillna(0)\n",
    "        else:\n",
    "            feed.append_dist_to_stop_times_fast()\n",
    "for feed in feeds_t:            \n",
    "    if feed.stop_times['shape_dist_traveled'].max() < 100:\n",
    "        print(f'convert to meters')\n",
    "        feed.dist_units = 'km'\n",
    "        feed = gtk.convert_dist(feed, new_dist_units='m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e7a439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf29e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0c681f1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "CPU times: user 319 ms, sys: 57 ms, total: 376 ms\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feeds_frequencies = []\n",
    "\n",
    "for i in range(len(feeds_t)):\n",
    "    print(i)\n",
    "    feed_s = feeds_t[i].copy()\n",
    "    feed_s.group_services()\n",
    "\n",
    "    feed_s.build_stop_clusters(distance_threshold=50)\n",
    "    feed_s.build_patterns(on='cluster_id')\n",
    "\n",
    "    feed_frequencies = feed_s.convert_to_frequencies(time_range=time_range)\n",
    "    shapes = feed_frequencies.shapes is not None\n",
    "    feed_frequencies.build_links_and_nodes(log=False, \n",
    "                                           shape_dist_traveled=True, \n",
    "                                           from_shape=shapes, \n",
    "                                           stick_nodes_on_links=shapes,\n",
    "                                           num_cores=4,\n",
    "                                           keep_origin_columns=['departure_time','pickup_type'],\n",
    "                                           keep_destination_columns=['arrival_time','drop_off_type'])\n",
    "    feeds_frequencies.append(feed_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6058ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2e761bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {0:'tram', 1:'subway', 2:'rail', 3:'bus',4:'ferry',5:'cable_car',6:'gondola',7:'funicular', 700:'bus', 1501:'taxi'}\n",
    "retire = ['taxi']\n",
    "for feed_frequencies in feeds_frequencies:\n",
    "    feed_frequencies.links['route_type'] = feed_frequencies.links['route_type'].apply(\n",
    "        lambda t: mapping.get(t, np.nan)\n",
    "    )\n",
    "    \n",
    "    assert not any(feed_frequencies.links['route_type'].isna())\n",
    "    feed_frequencies.links = feed_frequencies.links[~feed_frequencies.links['route_type'].isin(retire)]\n",
    "\n",
    "for feed_frequencies in feeds_frequencies:\n",
    "    feed_frequencies.links.loc[feed_frequencies.links['time'] == 0,'time'] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feafd07",
   "metadata": {},
   "source": [
    "# create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c01f7e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['trip_id','route_id','agency_id','direction_id','a','b', 'shape_dist_traveled',\n",
    "                                    'link_sequence','time','headway','pickup_type', 'drop_off_type',\n",
    "                                    'route_short_name','route_type','route_color','geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595a005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b8f8dd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot determine common CRS for concatenation inputs, got ['WGS 84 / UTM zone 10N', 'WGS 84 / UTM zone 18N']. Use `to_crs()` to transform geometries to the same CRS before merging.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(links_concat)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m sm\u001b[38;5;241m.\u001b[39mlinks \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinks_concat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sm\u001b[38;5;241m.\u001b[39mlinks\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/quetzal-77-onnKO/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/quetzal-77-onnKO/lib/python3.8/site-packages/pandas/core/reshape/concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    368\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    369\u001b[0m     objs,\n\u001b[1;32m    370\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    379\u001b[0m )\n\u001b[0;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/quetzal-77-onnKO/lib/python3.8/site-packages/pandas/core/reshape/concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    614\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 616\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy:\n\u001b[1;32m    620\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/quetzal-77-onnKO/lib/python3.8/site-packages/pandas/core/internals/concat.py:226\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    223\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mconcat_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     values \u001b[38;5;241m=\u001b[39m ensure_block_shape(values, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    229\u001b[0m values \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(values)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/quetzal-77-onnKO/lib/python3.8/site-packages/pandas/core/dtypes/concat.py:133\u001b[0m, in \u001b[0;36mconcat_compat\u001b[0;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(to_concat[\u001b[38;5;241m0\u001b[39m], ABCExtensionArray):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# TODO: what about EA-backed Index?\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(to_concat[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concat_same_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate(to_concat)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/quetzal-77-onnKO/lib/python3.8/site-packages/geopandas/array.py:1401\u001b[0m, in \u001b[0;36mGeometryArray._concat_same_type\u001b[0;34m(cls, to_concat)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;124;03mConcatenate multiple array\u001b[39;00m\n\u001b[1;32m   1391\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1398\u001b[0m \u001b[38;5;124;03mExtensionArray\u001b[39;00m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1400\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([ga\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;28;01mfor\u001b[39;00m ga \u001b[38;5;129;01min\u001b[39;00m to_concat])\n\u001b[0;32m-> 1401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GeometryArray(data, crs\u001b[38;5;241m=\u001b[39m\u001b[43m_get_common_crs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/quetzal-77-onnKO/lib/python3.8/site-packages/geopandas/array.py:1493\u001b[0m, in \u001b[0;36m_get_common_crs\u001b[0;34m(arr_seq)\u001b[0m\n\u001b[1;32m   1486\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1487\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRS not set for some of the concatenation inputs. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1488\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting output\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms CRS as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnames[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1489\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(the single non-null crs provided).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1490\u001b[0m         )\n\u001b[1;32m   1491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m crs_not_none[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1493\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot determine common CRS for concatenation inputs, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnames\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `to_crs()` to transform geometries to the same CRS before merging.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1496\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot determine common CRS for concatenation inputs, got ['WGS 84 / UTM zone 10N', 'WGS 84 / UTM zone 18N']. Use `to_crs()` to transform geometries to the same CRS before merging."
     ]
    }
   ],
   "source": [
    "sm = stepmodel.StepModel(epsg=4326, coordinates_unit='meter')\n",
    "\n",
    "links_concat = []; nodes_concat = []\n",
    "for feed_frequencies in feeds_frequencies:\n",
    "    links_concat.append(feed_frequencies.links)\n",
    "    nodes_concat.append(feed_frequencies.nodes)\n",
    "if len(links_concat)==0:\n",
    "    print('gg')\n",
    "    \n",
    "sm.links = pd.concat(links_concat)\n",
    "for col in columns:\n",
    "    if col not in sm.links.columns:\n",
    "        sm.links[col] = np.nan\n",
    "        \n",
    "sm.links = sm.links[columns]\n",
    "sm.nodes = pd.concat(nodes_concat)[['stop_id','stop_name','stop_code','geometry']]\n",
    "\n",
    "sm.nodes = sm.nodes.reset_index(drop=True).sort_index()\n",
    "sm.links = sm.links.reset_index(drop=True).sort_index()\n",
    "\n",
    "\n",
    "sm.nodes.loc[sm.nodes['stop_code'].isna(),'stop_code'] = sm.nodes.loc[sm.nodes['stop_code'].isna(),'stop_id'] \n",
    "sm.nodes.drop_duplicates(subset=['stop_id'], inplace=True)\n",
    "\n",
    "sm.links['trip_id'] = sm.links['agency_id'] +'_' +sm.links['trip_id']\n",
    "sm.links['route_id'] = sm.links['agency_id'] +'_' +sm.links['route_id']\n",
    "\n",
    "sm.links = sm.links.sort_values(['route_type','trip_id']).reset_index(drop=True)\n",
    "\n",
    "dnodes = ('node_' +sm.nodes.reset_index().set_index('stop_id')['index'].astype(str)).to_dict()\n",
    "sm.nodes.index = 'node_' +sm.nodes.index.astype(str)\n",
    "\n",
    "sm.links.index = 'link_' +sm.links.index.astype(str)\n",
    "\n",
    "sm.links['a'] = sm.links['a'].apply(lambda a: dnodes.get(a))\n",
    "sm.links['b'] = sm.links['b'].apply(lambda a: dnodes.get(a))\n",
    "\n",
    "sm.links.drop_duplicates(subset=['trip_id','link_sequence'], inplace=True)\n",
    "\n",
    "# Tag route with only one trip\n",
    "time_slot = np.diff([hhmmss_to_seconds_since_midnight(time) for time in time_range])[0]\n",
    "sm.links.loc[(time_slot/sm.links['headway']) < 2.0, 'headway'] = np.nan\n",
    "\n",
    "sm.links = sm.links.to_crs(4326)\n",
    "sm.nodes = sm.nodes.to_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f3607f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.GeoDataFrame(columns=['feature'], geometry='feature',crs=4326).to_file('test.geojson',driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741dbeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aac050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf58074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28a81c76",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fada4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b27171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b5238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f623f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f760e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a4abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227279d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed98bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e53279a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6000012"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambda price for 10GB per hours\n",
    "price = 0.0000166667*60*60*10\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d9a90384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.000024"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1195cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c82dee78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.11111111111111"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400_000/60/60/10 #heures gratuites a 10gb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4650826e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36f6d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with EB EC2 t3.xlarge:\n",
    "# 4 cores,m 16bg\n",
    "price = 0.1856 #per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "38357a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.568"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee912a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plan de match:\n",
    "si on a pas de shape_dist_traveled. prendre le temps avec les stop_time comme dist.\n",
    "(la methode 2 de gtfs_kit quand ca marche pas)\n",
    "\n",
    "anyway. on va recalculer avec le shape avec la methode a simon f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "35f8850c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.parallel.<locals>.decorator.<locals>.wrapper(*args, **kwargs)>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "fc4af97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel import parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "cef0b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager\n",
    "\n",
    "def parallel(loop_arg,num_cores=2):\n",
    "    def decorator(func):\n",
    "        def wrapper(**kwargs):\n",
    "            print(num_cores)\n",
    "            if num_cores==1:\n",
    "                return func(**kwargs)\n",
    "            else:\n",
    "                ls = kwargs.pop(loop_arg)\n",
    "                chunk_length =  round(len(ls)/ num_cores)\n",
    "                chunks = [ls[j: j + chunk_length] for j in range(0, len(ls), chunk_length)]\n",
    "                \n",
    "                def process_wrapper(chunk, kwargs, result_list, index):\n",
    "                    kwargs[loop_arg] = chunk\n",
    "                    result = func(**kwargs)\n",
    "                    result_list[index] = result\n",
    "                manager = Manager()\n",
    "                result_list = manager.list([None] * len(chunks))\n",
    "                processes = []\n",
    "                for i, chunk in enumerate(chunks):\n",
    "                    process = Process(target=process_wrapper, args=(chunk, kwargs, result_list, i))\n",
    "                    process.start()\n",
    "                    processes.append(process)\n",
    "                for process in processes:\n",
    "                    process.join()\n",
    "                # Convert the manager list to a regular list for easier access\n",
    "                result_list = np.array(result_list)\n",
    "                if result_list.ndim==1:\n",
    "                    return result_list\n",
    "                else:\n",
    "                    tuple_len = result_list.shape[1]\n",
    "                    return tuple(res[:][i] for i in range(tuple_len))\n",
    "                 \n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "01576b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@parallel(num_cores=2,loop_arg='trip_list')\n",
    "def test(links,trip_list,constant):\n",
    "    result = []\n",
    "    for trip in trip_list:\n",
    "        links = sm.links[sm.links['trip_id']==trip]\n",
    "        res = links['headway'].values.sum() + constant\n",
    "        result.append((trip,res))\n",
    "    return result,'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "db7cbfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "trip_list =  sm.links['trip_id'].unique()\n",
    "# calling the function\n",
    "res1,res2 = test(links=sm.links, trip_list=trip_list, constant=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33013ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "2cc2f381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f57d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d4539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0a1276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tasks(tasks,col=None,time_range=[],colors=['dodgerblue','tab:blue','cadetblue','darkturquoise','powderblue']):\n",
    "    # start_time, 'time','index'\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.lines import Line2D\n",
    "    from matplotlib.colors import ColorConverter\n",
    "    f, ax = plt.subplots(figsize=(15,12))\n",
    "    w=0.8\n",
    "    if 'index' not in tasks.columns:\n",
    "        tasks = tasks.reset_index()\n",
    "    if col:\n",
    "        tasks = tasks.sort_values(col)\n",
    "        line_ids = tasks[col].unique()\n",
    "        \n",
    "        for i,line_id in enumerate(tasks[col].unique()):\n",
    "            task = tasks[tasks[col]==line_id]\n",
    "            ax.barh(task['index'],task['time'],height=w , left=task['start_time'],color=colors[i])\n",
    "            \n",
    "        legend_elements = [Line2D([0], [0], color=colors[i], lw=4, label=line_ids[i]) for i in range(len(line_ids))]\n",
    "\n",
    "        ax.legend(handles=legend_elements,prop={\"size\":16})\n",
    "    else:\n",
    "        ax.barh(tasks['index'],tasks['time'],height=w , left=tasks['start_time'])\n",
    "            # y position (bus number) ,   #length (task duration),   height ,           x position (start_time)\n",
    "\n",
    "\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('trip number')\n",
    "\n",
    "    ##### labels ####\n",
    "    if len(time_range)>0:\n",
    "        plt.axvline(x = time_range[0], color = 'r', label = 'axvline - full height')\n",
    "        plt.axvline(x = time_range[1], color = 'r', label = 'axvline - full height')\n",
    "\n",
    "\n",
    "    ##### TICKS #####\n",
    "    start_tick = int(np.floor(tasks['start_time'].min()/60/60)*60*60-60*60)\n",
    "    end_tick = int(np.ceil(tasks['end_time'].max()/60/60)*60*60)\n",
    "\n",
    "    xticks = np.arange(start_tick,end_tick,3600)\n",
    "    xticks_minor = np.arange(start_tick,end_tick,3600/2)\n",
    "\n",
    "    xticks_labels = xticks//3600\n",
    "    xticks_labels[xticks_labels>=24] = xticks_labels[xticks_labels>=24]-24\n",
    "    xticks_labels = [str(x)+'H00' for x in xticks_labels]\n",
    "\n",
    "\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticks(xticks_minor, minor=True)\n",
    "    ax.set_xticklabels(xticks_labels)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7412c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "time_range=['6:00:00', '9:59:00']\n",
    "feed = feeds[1].copy()\n",
    "feed = feed.restrict(['20190625'],time_range=time_range)\n",
    "res = feed.stop_times.groupby('trip_id')['departure_time'].agg(['first','last']).sort_values('first')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e76524",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "res['start_time']=res['first'].apply(lambda x : hhmmss_to_seconds_since_midnight(x))\n",
    "res['end_time']=res['last'].apply(lambda x : hhmmss_to_seconds_since_midnight(x))\n",
    "res['time'] = res['end_time'] - res['start_time']\n",
    "plot_tasks(res.reset_index(),time_range=[hhmmss_to_seconds_since_midnight(x) for x in time_range])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ea0650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "72512c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = feeds_t[0].copy()\n",
    "self.append_dist_to_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a256451d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<quetzal.io.gtfs_reader.importer.GtfsImporter at 0x7ff81f2b7040>]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "25e49685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import transform\n",
    "self = feeds_t[0].copy()\n",
    "epsg = importer.get_epsg(self.stops.iloc[1]['stop_lat'], self.stops.iloc[1]['stop_lon'])\n",
    "self.shapes['shape_pt_x'],self.shapes['shape_pt_y'] = transform(4326, epsg, self.shapes['shape_pt_lat'],self.shapes['shape_pt_lon'])\n",
    "#get distance between each points\n",
    "self.shapes = self.shapes.sort_values(['shape_id','shape_pt_sequence']).reset_index(drop=True)\n",
    "self.shapes['geom'] = self.shapes[['shape_pt_y','shape_pt_x']].apply(tuple,axis=1)\n",
    "self.shapes['previous_geom'] = self.shapes['geom'].shift(+1).fillna(method='bfill')\n",
    "\n",
    "\n",
    "self.shapes['dist'] = self.shapes[['previous_geom','geom']].apply(lambda x: importer.euclidean_distance(x[0],x[1]), axis=1)\n",
    "# cumsum the dist minus the first one (should be 0 but its not due to the batch operation)\n",
    "self.shapes['shape_dist_traveled'] = self.shapes.groupby('shape_id')['dist'].apply(importer.cumulative_minus_first)\n",
    "self.shapes = self.shapes.drop(columns=['shape_pt_x','shape_pt_y','geom','previous_geom','dist'])\n",
    "if self.dist_units == 'km':\n",
    "    self.shapes['shape_dist_traveled'] = self.shapes['shape_dist_traveled']/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e1d75237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shape_id</th>\n",
       "      <th>shape_pt_lat</th>\n",
       "      <th>shape_pt_lon</th>\n",
       "      <th>shape_pt_sequence</th>\n",
       "      <th>shape_dist_traveled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>396</td>\n",
       "      <td>48.39229</td>\n",
       "      <td>-77.24439</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>396</td>\n",
       "      <td>48.39146</td>\n",
       "      <td>-77.24048</td>\n",
       "      <td>2</td>\n",
       "      <td>303.902648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>396</td>\n",
       "      <td>48.39090</td>\n",
       "      <td>-77.23902</td>\n",
       "      <td>3</td>\n",
       "      <td>428.670935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>396</td>\n",
       "      <td>48.39014</td>\n",
       "      <td>-77.23789</td>\n",
       "      <td>4</td>\n",
       "      <td>547.599337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>396</td>\n",
       "      <td>48.38935</td>\n",
       "      <td>-77.23723</td>\n",
       "      <td>5</td>\n",
       "      <td>648.123082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13824</th>\n",
       "      <td>554</td>\n",
       "      <td>45.44828</td>\n",
       "      <td>-73.73928</td>\n",
       "      <td>65</td>\n",
       "      <td>4875.375400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13825</th>\n",
       "      <td>554</td>\n",
       "      <td>45.44855</td>\n",
       "      <td>-73.74083</td>\n",
       "      <td>66</td>\n",
       "      <td>5000.253877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13826</th>\n",
       "      <td>554</td>\n",
       "      <td>45.44865</td>\n",
       "      <td>-73.74096</td>\n",
       "      <td>67</td>\n",
       "      <td>5015.314400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13827</th>\n",
       "      <td>554</td>\n",
       "      <td>45.44866</td>\n",
       "      <td>-73.74127</td>\n",
       "      <td>68</td>\n",
       "      <td>5039.584048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13828</th>\n",
       "      <td>554</td>\n",
       "      <td>45.44889</td>\n",
       "      <td>-73.74127</td>\n",
       "      <td>69</td>\n",
       "      <td>5065.139194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13829 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence  \\\n",
       "0          396      48.39229     -77.24439                  1   \n",
       "1          396      48.39146     -77.24048                  2   \n",
       "2          396      48.39090     -77.23902                  3   \n",
       "3          396      48.39014     -77.23789                  4   \n",
       "4          396      48.38935     -77.23723                  5   \n",
       "...        ...           ...           ...                ...   \n",
       "13824      554      45.44828     -73.73928                 65   \n",
       "13825      554      45.44855     -73.74083                 66   \n",
       "13826      554      45.44865     -73.74096                 67   \n",
       "13827      554      45.44866     -73.74127                 68   \n",
       "13828      554      45.44889     -73.74127                 69   \n",
       "\n",
       "       shape_dist_traveled  \n",
       "0                 0.000000  \n",
       "1               303.902648  \n",
       "2               428.670935  \n",
       "3               547.599337  \n",
       "4               648.123082  \n",
       "...                    ...  \n",
       "13824          4875.375400  \n",
       "13825          5000.253877  \n",
       "13826          5015.314400  \n",
       "13827          5039.584048  \n",
       "13828          5065.139194  \n",
       "\n",
       "[13829 rows x 5 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.shapes.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d783c39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shape_id</th>\n",
       "      <th>shape_pt_lat</th>\n",
       "      <th>shape_pt_lon</th>\n",
       "      <th>shape_pt_sequence</th>\n",
       "      <th>shape_dist_traveled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [shape_id, shape_pt_lat, shape_pt_lon, shape_pt_sequence, shape_dist_traveled]\n",
       "Index: []"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.shapes[self.shapes['shape_dist_traveled'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ac61161",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_epsg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mreturn self with self.shapes['shape_dist_traveled'] \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#transform coords to meters\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m epsg \u001b[38;5;241m=\u001b[39m \u001b[43mget_epsg\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstops\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop_lat\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstops\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop_lon\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# pyproj takes [y,x] and return [x,y].\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshapes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape_pt_x\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshapes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape_pt_y\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m transform(\u001b[38;5;241m4326\u001b[39m, epsg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshapes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape_pt_lat\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshapes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape_pt_lon\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_epsg' is not defined"
     ]
    }
   ],
   "source": [
    " '''\n",
    "return self with self.shapes['shape_dist_traveled'] \n",
    "'''\n",
    "#transform coords to meters\n",
    "epsg = get_epsg(self.stops.iloc[1]['stop_lat'], self.stops.iloc[1]['stop_lon'])\n",
    "# pyproj takes [y,x] and return [x,y].\n",
    "self.shapes['shape_pt_x'],self.shapes['shape_pt_y'] = transform(4326, epsg, self.shapes['shape_pt_lat'],self.shapes['shape_pt_lon'])\n",
    "\n",
    "#get distance between each points\n",
    "self.shapes = self.shapes.sort_values(['shape_id','shape_pt_sequence']).reset_index(drop=True)\n",
    "self.shapes['geom'] = self.shapes[['shape_pt_y','shape_pt_x']].apply(tuple,axis=1)\n",
    "self.shapes['previous_geom'] = self.shapes['geom'].shift(+1).fillna(method='bfill')\n",
    "\n",
    "self.shapes['dist'] = self.shapes[['previous_geom','geom']].apply(lambda x: euclidean_distance(x[0],x[1]), axis=1)\n",
    "# cumsum the dist minus the first one (should be 0 but its not due to the batch operation)\n",
    "self.shapes['shape_dist_traveled'] = self.shapes.groupby('shape_id')['dist'].apply(cumulative_minus_first)\n",
    "\n",
    "self.shapes = self.shapes.drop(columns=['shape_pt_x','shape_pt_y','geom','previous_geom','dist'])\n",
    "if self.dist_units == 'km':\n",
    "    self.shapes['shape_dist_traveled'] = self.shapes['shape_dist_traveled']/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23eb4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quetzal_env",
   "language": "python",
   "name": "quetzal_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
